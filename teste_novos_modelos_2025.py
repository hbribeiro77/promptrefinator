#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste dos Novos Modelos de IA - 2025

Este script testa se os novos modelos de IA est√£o sendo carregados corretamente
na aplica√ß√£o PromptRefinator2.

Autor: Assistant
Data: Janeiro 2025
"""

import sys
import os
from typing import List, Dict, Any

# Adicionar o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from services.openai_service import OpenAIService
from services.azure_service import AzureService
from services.ai_manager_service import AIManagerService

def testar_modelos_config():
    """Testar se os modelos est√£o definidos corretamente no config"""
    print("=== TESTE: Modelos no Config ===")
    
    print(f"\nüìã Modelos OpenAI ({len(Config.OPENAI_MODELS)} modelos):")
    for i, modelo in enumerate(Config.OPENAI_MODELS, 1):
        print(f"  {i:2d}. {modelo}")
    
    print(f"\nüìã Modelos Azure OpenAI ({len(Config.AZURE_OPENAI_MODELS)} modelos):")
    for i, modelo in enumerate(Config.AZURE_OPENAI_MODELS, 1):
        print(f"  {i:2d}. {modelo}")
    
    # Verificar se os novos modelos est√£o presentes
    novos_modelos_openai = [
        'gpt-5', 'gpt-5-mini', 'gpt-4.1', 'gpt-4o', 'o3', 'o4-mini'
    ]
    
    novos_modelos_azure = [
        'gpt-5', 'gpt-5-mini', 'gpt-4.1', 'gpt-4o', 'o3-mini', 'gpt-oss-120b'
    ]
    
    print("\n‚úÖ Verifica√ß√£o de Novos Modelos OpenAI:")
    for modelo in novos_modelos_openai:
        status = "‚úÖ" if modelo in Config.OPENAI_MODELS else "‚ùå"
        print(f"  {status} {modelo}")
    
    print("\n‚úÖ Verifica√ß√£o de Novos Modelos Azure:")
    for modelo in novos_modelos_azure:
        status = "‚úÖ" if modelo in Config.AZURE_OPENAI_MODELS else "‚ùå"
        print(f"  {status} {modelo}")
    
    return True  # Retornar True se chegou at√© aqui

def testar_servicos_ia():
    """Testar se os servi√ßos de IA carregam os modelos corretamente"""
    print("\n=== TESTE: Servi√ßos de IA ===")
    
    try:
        # Testar OpenAI Service
        print("\nüîß Testando OpenAI Service...")
        openai_service = OpenAIService()
        modelos_openai = openai_service.get_available_models()
        print(f"‚úÖ OpenAI Service carregado com {len(modelos_openai)} modelos")
        
        # Testar Azure Service
        print("\nüîß Testando Azure Service...")
        azure_service = AzureService()
        modelos_azure = azure_service.get_available_models()
        print(f"‚úÖ Azure Service carregado com {len(modelos_azure)} modelos")
        
        # Testar AI Manager
        print("\nüîß Testando AI Manager Service...")
        ai_manager = AIManagerService()
        provedores = ai_manager.get_available_providers()
        print(f"‚úÖ AI Manager carregado com provedores: {', '.join(provedores)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao testar servi√ßos: {e}")
        return False

def testar_estimativas_custo():
    """Testar se as estimativas de custo est√£o funcionando para os novos modelos"""
    print("\n=== TESTE: Estimativas de Custo ===")
    
    try:
        openai_service = OpenAIService()
        azure_service = AzureService()
        
        # Modelos para testar
        modelos_teste = [
            'gpt-5', 'gpt-5-mini', 'gpt-4.1', 'gpt-4o', 'o3', 'o4-mini', 'gpt-4'
        ]
        
        prompt_length = 1000  # caracteres
        response_length = 500  # caracteres
        
        print("\nüí∞ Estimativas de Custo: DESABILITADAS")
        print("   Simula√ß√£o de custos foi removida do sistema.")
        print("   Os custos reais ser√£o cobrados diretamente pela OpenAI/Azure.")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao testar estimativas de custo: {e}")
        return False

def testar_parametros_padrao():
    """Testar se os par√¢metros padr√£o est√£o corretos"""
    print("\n=== TESTE: Par√¢metros Padr√£o ===")
    
    try:
        openai_service = OpenAIService()
        azure_service = AzureService()
        
        print("\n‚öôÔ∏è Par√¢metros Padr√£o OpenAI:")
        params_openai = openai_service.get_default_parameters()
        for key, value in params_openai.items():
            print(f"  {key:15} ‚Üí {value}")
        
        print("\n‚öôÔ∏è Par√¢metros Padr√£o Azure:")
        params_azure = azure_service.get_default_parameters()
        for key, value in params_azure.items():
            print(f"  {key:15} ‚Üí {value}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao testar par√¢metros padr√£o: {e}")
        return False

def gerar_relatorio_modelos():
    """Gerar relat√≥rio detalhado dos modelos dispon√≠veis"""
    print("\n=== RELAT√ìRIO: Modelos Dispon√≠veis ===")
    
    # Categorizar modelos
    categorias = {
        'GPT-5 Series': [m for m in Config.OPENAI_MODELS if m.startswith('gpt-5')],
        'GPT-4.1 Series': [m for m in Config.OPENAI_MODELS if m.startswith('gpt-4.1')],
        'GPT-4o Series': [m for m in Config.OPENAI_MODELS if 'gpt-4o' in m],
        'o-Series (Reasoning)': [m for m in Config.OPENAI_MODELS if m.startswith('o')],
        'GPT-4 Legacy': [m for m in Config.OPENAI_MODELS if m.startswith('gpt-4') and not m.startswith('gpt-4.1') and 'gpt-4o' not in m],
        'GPT-3.5 Series': [m for m in Config.OPENAI_MODELS if m.startswith('gpt-3.5')]
    }
    
    print("\nüìä Modelos OpenAI por Categoria:")
    for categoria, modelos in categorias.items():
        if modelos:
            print(f"\n  üè∑Ô∏è {categoria} ({len(modelos)} modelos):")
            for modelo in modelos:
                print(f"    ‚Ä¢ {modelo}")
    
    # Azure espec√≠ficos
    azure_exclusivos = [m for m in Config.AZURE_OPENAI_MODELS if m not in Config.OPENAI_MODELS]
    if azure_exclusivos:
        print(f"\n  üè∑Ô∏è Modelos Exclusivos do Azure ({len(azure_exclusivos)} modelos):")
        for modelo in azure_exclusivos:
            print(f"    ‚Ä¢ {modelo}")

def main():
    """Fun√ß√£o principal do teste"""
    print("üöÄ TESTE DOS NOVOS MODELOS DE IA - 2025")
    print("=" * 50)
    
    # Executar todos os testes
    testes = [
        ("Modelos no Config", testar_modelos_config),
        ("Servi√ßos de IA", testar_servicos_ia),
        ("Estimativas de Custo", testar_estimativas_custo),
        ("Par√¢metros Padr√£o", testar_parametros_padrao)
    ]
    
    resultados = []
    
    for nome_teste, funcao_teste in testes:
        try:
            print(f"\nüß™ Executando: {nome_teste}")
            resultado = funcao_teste()
            resultados.append((nome_teste, resultado))
        except Exception as e:
            print(f"‚ùå Erro no teste '{nome_teste}': {e}")
            resultados.append((nome_teste, False))
    
    # Gerar relat√≥rio
    gerar_relatorio_modelos()
    
    # Resumo final
    print("\n" + "=" * 50)
    print("üìã RESUMO DOS TESTES")
    print("=" * 50)
    
    testes_passou = 0
    for nome_teste, resultado in resultados:
        status = "‚úÖ PASSOU" if resultado else "‚ùå FALHOU"
        print(f"  {nome_teste:25} ‚Üí {status}")
        if resultado:
            testes_passou += 1
    
    print(f"\nüéØ Resultado Final: {testes_passou}/{len(resultados)} testes passaram")
    
    if testes_passou == len(resultados):
        print("\nüéâ Todos os testes passaram! Os novos modelos est√£o configurados corretamente.")
    else:
        print("\n‚ö†Ô∏è Alguns testes falharam. Verifique os erros acima.")
    
    print("\nüìö Para mais informa√ß√µes, consulte: documentacao_modelos_ia_2025.md")
    print("\n" + "=" * 50)

if __name__ == "__main__":
    main()